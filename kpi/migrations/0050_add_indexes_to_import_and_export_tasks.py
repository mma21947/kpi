# Generated by Django 3.2.15 on 2023-05-18 21:37

import django.contrib.postgres.indexes
import django.db.models.expressions
from django.conf import settings
from django.db import migrations


def manually_create_indexes_instructions(apps, schema_editor):
    print(
        """
        !!! ATTENTION !!!
        You need to run the SQL queries below in PostgreSQL directly:

            > CREATE INDEX CONCURRENTLY "data__destination_idx" ON "kpi_importtask" USING btree ((("data" -> 'destination')));
            > CREATE INDEX CONCURRENTLY "data__source_idx" ON "kpi_exporttask" USING btree ((("data" -> 'source')));

            > CREATE INDEX CONCURRENTLY "data__destination_hash_idx" ON "kpi_importtask" USING hash ((("data" -> 'destination')));
            > CREATE INDEX CONCURRENTLY "data__source_hash_idx" ON "kpi_exporttask" USING hash ((("data" -> 'source')));

        Otherwise, project deletions will perform very poorly.

        You may create one index per table simultaneously, i.e. you may run the
        first two queries in parallel (within different psql sessions) and then
        run the next two in parallel afterwards. You cannot run all of them
        at the same time.
        """
    )


def manually_drop_indexes_instructions(apps, schema_editor):
    print(
        """
        !!! ATTENTION !!!
        Run the SQL queries below in PostgreSQL directly:

            > DROP INDEX CONCURRENTLY IF EXISTS "data__destination_idx";
            > DROP INDEX CONCURRENTLY IF EXISTS "data__source_idx";

            > DROP INDEX CONCURRENTLY IF EXISTS "data__destination_hash_idx";
            > DROP INDEX CONCURRENTLY IF EXISTS "data__source_hash_idx";

        You may remove one index per table simultaneously, i.e. you may run the
        first two queries in parallel (within different psql sessions) and then
        run the next two in parallel afterwards. You cannot run all of them
        at the same time.
        """
    )

def warning_long_run(apps, schema_editor):
    print(
        """
        This might take a while. If it is too slow, you may want to
        interrupt this migration, cancel any outstanding `CREATEâ€¦` or `DROP
        INDEX` queries on `kpi_importtask` and `kpi_exporttask`, re-run the
        migration with `SKIP_HEAVY_MIGRATIONS=True`, and then follow the
        printed instructions to set up the indexes concurrently (without
        downtime) using raw SQL.
        """
    )


class Migration(migrations.Migration):

    dependencies = [
        ('kpi', '0049_add_pending_delete_to_asset'),
    ]

    if not settings.SKIP_HEAVY_MIGRATIONS:
        operations = [
            migrations.RunPython(warning_long_run, warning_long_run),
            migrations.AddIndex(
                model_name='importtask',
                index=django.contrib.postgres.indexes.BTreeIndex(
                    django.db.models.expressions.F('data__destination'),
                    name='data__destination_idx',
                ),
            ),
            migrations.AddIndex(
                model_name='importtask',
                index=django.contrib.postgres.indexes.HashIndex(
                    django.db.models.expressions.F('data__destination'),
                    name='data__destination_hash_idx',
                ),
            ),
            migrations.AddIndex(
                model_name='exporttask',
                index=django.contrib.postgres.indexes.BTreeIndex(
                    django.db.models.expressions.F('data__source'), name='data__source_idx'),
            ),
            migrations.AddIndex(
                model_name='exporttask',
                index=django.contrib.postgres.indexes.HashIndex(
                    django.db.models.expressions.F('data__source'),
                    name='data__source_hash_idx'),
            ),
        ]
    else:
        operations = [
            migrations.RunPython(
                manually_create_indexes_instructions,
                manually_drop_indexes_instructions,
            )
        ]
